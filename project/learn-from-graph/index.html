<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Shadi Albarqouni">

  
  
  
    
  
  <meta name="description" content="Manifold Learning, Graph Convolutional Networks">

  
  <link rel="alternate" hreflang="en-us" href="https://albarqouni.github.io/project/learn-from-graph/">

  


  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  





<script async src="https://www.googletagmanager.com/gtag/js?id=UA-73880662-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'UA-73880662-2', {});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  


  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu681563d5489cbd6b4a3381f376416aae_52869_32x32_fill_lanczos_center_3.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu681563d5489cbd6b4a3381f376416aae_52869_192x192_fill_lanczos_center_3.png">

  <link rel="canonical" href="https://albarqouni.github.io/project/learn-from-graph/">

  
  
  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@ShadiAlbarqouni">
  <meta property="twitter:creator" content="@ShadiAlbarqouni">
  
  <meta property="og:site_name" content="Shadi Albarqouni">
  <meta property="og:url" content="https://albarqouni.github.io/project/learn-from-graph/">
  <meta property="og:title" content="Learn from Prior Knowledge | Shadi Albarqouni">
  <meta property="og:description" content="Manifold Learning, Graph Convolutional Networks"><meta property="og:image" content="https://albarqouni.github.io/project/learn-from-graph/featured.jpg">
  <meta property="twitter:image" content="https://albarqouni.github.io/project/learn-from-graph/featured.jpg"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2020-04-06T00:00:00&#43;00:00">
    
    <meta property="article:modified_time" content="2020-04-12T00:45:50&#43;02:00">
  

  


    









<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://albarqouni.github.io/project/learn-from-graph/"
  },
  "headline": "Learn from Prior Knowledge",
  
  "image": [
    "https://albarqouni.github.io/project/learn-from-graph/featured.jpg"
  ],
  
  "datePublished": "2020-04-06T00:00:00Z",
  "dateModified": "2020-04-12T00:45:50+02:00",
  
  "author": {
    "@type": "Person",
    "name": "Shadi Albarqouni"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Shadi Albarqouni",
    "logo": {
      "@type": "ImageObject",
      "url": "https://albarqouni.github.io/images/icon_hu681563d5489cbd6b4a3381f376416aae_52869_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "Manifold Learning, Graph Convolutional Networks"
}
</script>

  

  


  


  





  <title>Learn from Prior Knowledge | Shadi Albarqouni</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  







<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Shadi Albarqouni</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Shadi Albarqouni</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#experience"><span>Resume</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Research</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#talks"><span>Community</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#featured"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#people"><span>Team</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/students/"><span>Students</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/codes/"><span>Codes</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/team/"><span>Open Positions</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      

      

    </ul>

  </div>
</nav>


  <article class="article article-project">

  




















  
  


<div class="article-container pt-3">
  <h1>Learn from Prior Knowledge</h1>

  

  


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
          Last updated on
      
    
    Apr 12, 2020
  </span>
  

  

  

  
  
  

  
  

</div>

  













<div class="btn-links mb-3">
  
  








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1" href="https://twitter.com/ShadiAlbarqouni" target="_blank" rel="noopener">
    <i class="fab fa-twitter mr-1"></i>
    Follow
  </a>

  
  
  
    
  
  
  
  
  
    
    
      
    
  
  <a class="btn btn-outline-primary my-1 mr-1" href="/#contact" >
    <i class="fab fa-code mr-1"></i>
    Contribute
  </a>


</div>


</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 697px; max-height: 689px;">
  <div style="position: relative">
    <img src="/project/learn-from-graph/featured.jpg" alt="" class="featured-image">
    <span class="article-header-caption">Illustrative figure by Shadi Albarqouni</span>
  </div>
</div>



  <div class="article-container">

    <div class="article-style">
      <p>Together with our clinical and industry partners, we realized that there is a need to incorporate domain-specific knowledge and let the model <em>Learn from a Prior Knowledge</em>. We first investigated modeling general priors, i.e., manifold assumptions, to learn powerful representations. Such representations achieved state-of-the-art on benchmark datasets, such as e IDRiD for Diabetic Retinopathy Early Detection (Sarhan <em>et al.</em> 2019), and 7 Scenes for Camera Relocalization (Bui <em>et al.</em> 2017). Then, we started looking into the laplacian graph, where prior knowledge can be modeled as a soft constraint, i.e., regularization, to learn feature representation that follows such manifold defined by graphs. We have shown in our ISBI (Kazi <em>et al.</em> 2019a), MICCAI (Kazi <em>et al.</em> 2019b), and IPMI (Kazi <em>et al.</em> 2019) papers that leveraging prior knowledge such as proximity of ages, gender, and a few lab results, are of high importance in Alzheimer classification.</p>
<h3 id="collaboration">Collaboration:</h3>
<ul>
<li></li>
</ul>
<h3 id="funding">Funding:</h3>
<ul>
<li>Siemens AG</li>
</ul>

    </div>

    





<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/deep-learning/">Deep Learning</a>
  
  <a class="badge badge-light" href="/tags/medical-imaging/">Medical Imaging</a>
  
</div>



<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://albarqouni.github.io/project/learn-from-graph/&amp;text=Learn%20from%20Prior%20Knowledge" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://albarqouni.github.io/project/learn-from-graph/&amp;t=Learn%20from%20Prior%20Knowledge" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Learn%20from%20Prior%20Knowledge&amp;body=https://albarqouni.github.io/project/learn-from-graph/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://albarqouni.github.io/project/learn-from-graph/&amp;title=Learn%20from%20Prior%20Knowledge" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=Learn%20from%20Prior%20Knowledge%20https://albarqouni.github.io/project/learn-from-graph/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https://albarqouni.github.io/project/learn-from-graph/&amp;title=Learn%20from%20Prior%20Knowledge" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>












  
  





  
  
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <img class="avatar mr-3 avatar-circle" src="/authors/admin/avatar_hud88bf5a68b63304b861af7343adde0d5_2791867_270x270_fill_q90_lanczos_center.jpg" alt="Shadi Albarqouni">
    

    <div class="media-body">
      <h5 class="card-title"><a href="/authors/admin/">Shadi Albarqouni</a></h5>
      <h6 class="card-subtitle">Professor of Computational Medical Imaging Research at 
<a href="https://www.uni-bonn.de/en" target="_blank" rel="noopener">University of Bonn</a> | AI Young Investigator Group Leader at 
<a href="https://www.helmholtz.ai/" target="_blank" rel="noopener">Helmholtz AI</a></h6>
      
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:shadi.albarqouni@tum.de" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://twitter.com/ShadiAlbarqouni" target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.de/citations?user=CPuApzoAAAAJ&amp;hl=en" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/albarqouni" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/shadialbarqouni/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://orcid.org/0000-0003-2157-2211" target="_blank" rel="noopener">
        <i class="ai ai-orcid"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://albarqouni.github.io/" target="_blank" rel="noopener">
        <i class="fas fa-globe-africa"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>












  
  
  <div class="article-widget content-widget-hr">
    <h3>Related</h3>
    <ul>
      
      <li><a href="/project/federated-learning/">Deep Federated Learning in Healthcare</a></li>
      
      <li><a href="/project/learn-from-crowds/">Learn from Crowds</a></li>
      
      <li><a href="/project/learn-to-adapt/">Learn to Adapt</a></li>
      
      <li><a href="/project/learn-to-learn/">Learn to Learn</a></li>
      
      <li><a href="/project/learn-to-reason-and-explain/">Learn to Reason and Explain</a></li>
      
    </ul>
  </div>
  



    <div class="project-related-pages content-widget-hr">
      
      

      
      
      

      
      
      
        <h2>Publications</h2>
        
          
            





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/authors/roger-d-soberanis-mukul/">Roger D Soberanis-Mukul</a></span>, <span><a href="/authors/nassir-navab/">Nassir Navab</a></span>, <span><a href="/authors/shadi-albarqouni/">Shadi Albarqouni</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    December 2020
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      <em>Journal of Machine Learning for Biomedical Imaging (MELBA) -Special Issue: Medical Imaging with Deep Learning</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/soberanis-2020-uncertainty/">
      <img src="/publication/soberanis-2020-uncertainty/featured_hu8036c18f58a658215ea001099786cf41_74839_918x517_fill_q90_lanczos_smart1_3.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/soberanis-2020-uncertainty/">An Uncertainty-Driven GCN Refinement Strategy for Organ Segmentation</a>
  </h3>

  
  <div class="article-style">
    <p>Organ segmentation in CT volumes is an important pre-processing step in many computer assisted intervention and diagnosis methods. In recent years, convolutional neural networks have dominated the state of the art in this task. However, since this problem presents a challenging environment due to high variability in the organ’s shape and similarity between tissues, the generation of false negative and false positive regions in the output segmentation is a common issue. Recent works have shown that the uncertainty analysis of the model can provide us with useful information about potential errors in the segmentation. In this context, we proposed a segmentation refinement method based on uncertainty analysis and graph convolutional networks. We employ the uncertainty levels of the convolutional network in a particular input volume to formulate a semi-supervised graph learning problem that is solved by training a graph convolutional network. To test our method we refine the initial output of a 2D U-Net. We validate our framework with the NIH pancreas dataset and the spleen dataset of the medical segmentation decathlon. We show that our method outperforms the state-of-the-art CRF refinement method by improving the dice score by 1% for the pancreas and 2% for spleen, with respect to the original U-Net’s prediction. Finally, we perform a sensitivity analysis on the parameters of our proposal and discuss the applicability to other CNN architectures, the results, and current limitations of the model for future work in this research direction. For reproducibility purposes, we make our code publicly available at 
<a href="https://github.com/rodsom22/gcn_refinement" target="_blank" rel="noopener">https://github.com/rodsom22/gcn_refinement</a></p>
  </div>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2012.03352v1" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/soberanis-2020-uncertainty/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/uncertainty/">
    Project
  </a>
  

  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-reason-and-explain/">
    Project
  </a>
  

  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-from-graph/">
    Project
  </a>
  











  </div>
  

</div>

          
        
          
            





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/authors/roger-d-soberanis-mukul/">Roger D Soberanis-Mukul</a></span>, <span><a href="/authors/nassir-navab/">Nassir Navab</a></span>, <span><a href="/authors/shadi-albarqouni/">Shadi Albarqouni</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    April 2020
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      <em>To appear in the International Conference in Medical Imaging with Deep Learning, 2020</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/soberanis-2019-uncertainty/">
      <img src="/publication/soberanis-2019-uncertainty/featured_hu6dab9400688a660bf7f8489ec42e9d3f_295410_918x517_fill_q90_lanczos_smart1_3.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/soberanis-2019-uncertainty/">Uncertainty-based graph convolutional networks for organ segmentation refinement</a>
  </h3>

  
  <div class="article-style">
    <p>Organ segmentation is an important pre-processing step in many computer assisted intervention and diagnosis methods. In recent years, CNNs have dominated the state of the art in this task. Organ segmentation scenarios present a challenging environment for these methods due to high variability in shape and similarity with background. This leads to the generation of false negative and false positive regions in the output segmentation. In this context, the uncertainty analysis of the model can provide us with useful information about potentially misclassified elements. In this work we propose a method based on uncertainty analysis and graph convolutional networks as a post-processing step for segmentation. For this, we employ the uncertainty levels of the CNN to formulate a semi-supervised graph learning problem that is solved by training a GCN on the low uncertainty elements. Finally, we evaluate the full graph on the trained GCN to get the refined segmentation. We test our framework in refining the output of pancreas and spleen segmentation models. We show that the framework can increase the average dice score in 1% and 2% respectively for these problems. Finally, we discuss the results and current limitations of the model that lead to future work in this research direction</p>
  </div>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/1906.02191" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/soberanis-2019-uncertainty/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/uncertainty/">
    Project
  </a>
  

  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-reason-and-explain/">
    Project
  </a>
  

  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-from-graph/">
    Project
  </a>
  











  </div>
  

</div>

          
        
          
            





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/authors/hendrik-burwinkel/">Hendrik Burwinkel</a></span>, <span><a href="/authors/anees-kazi/">Anees Kazi</a></span>, <span><a href="/authors/gerome-vivar/">Gerome Vivar</a></span>, <span><a href="/authors/shadi-albarqouni/">Shadi Albarqouni</a></span>, <span><a href="/authors/guillaume-zahnd/">Guillaume Zahnd</a></span>, <span><a href="/authors/nassir-navab/">Nassir Navab</a></span>, <span><a href="/authors/seyed-ahmad-ahmadi/">Seyed-Ahmad Ahmadi</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January 2019
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      <em>International Conference on Medical Image Computing and Computer-Assisted Intervention</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/burwinkel-2019-adaptive/">Adaptive image-feature learning for disease classification using inductive graph networks</a>
  </h3>

  
  <div class="article-style">
    <p>Recently, Geometric Deep Learning (GDL) has been introduced as a novel and versatile framework for computer-aided disease classification. GDL uses patient meta-information such as age and gender to model patient cohort relations in a graph structure. Concepts from graph signal processing are leveraged to learn the optimal mapping of multi-modal features, e.g. from images to disease classes. Related studies so far have considered image features that are extracted in a pre-processing step. We hypothesize that such an approach prevents the network from optimizing feature representations towards achieving the best performance in the graph network. We propose a new network architecture that exploits an inductive end-to-end learning approach for disease classification, where filters from both the CNN and the graph are trained jointly. We validate this architecture against state-of-the-art inductive graph networks and demonstrate significantly improved classification scores on a modified MNIST toy dataset, as well as comparable classification results with higher stability on a chest X-ray image dataset. Additionally, we explain how the structural information of the graph affects both the image filters and the feature learning.</p>
  </div>
  

  
  <div class="btn-links">
    








  





<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/burwinkel-2019-adaptive/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-from-graph/">
    Project
  </a>
  











  </div>
  

</div>

          
        
          
            





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/authors/anees-kazi/">Anees Kazi</a></span>, <span><a href="/authors/shayan-shekarforoush/">Shayan Shekarforoush</a></span>, <span><a href="/authors/s-arvind-krishna/">S Arvind Krishna</a></span>, <span><a href="/authors/hendrik-burwinkel/">Hendrik Burwinkel</a></span>, <span><a href="/authors/gerome-vivar/">Gerome Vivar</a></span>, <span><a href="/authors/benedict-wiestler/">Benedict Wiestler</a></span>, <span><a href="/authors/karsten-kortum/">Karsten Kortüm</a></span>, <span><a href="/authors/seyed-ahmad-ahmadi/">Seyed-Ahmad Ahmadi</a></span>, <span><a href="/authors/shadi-albarqouni/">Shadi Albarqouni</a></span>, <span><a href="/authors/nassir-navab/">Nassir Navab</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January 2019
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      <em>International Conference on Medical Image Computing and Computer-Assisted Intervention</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/kazi-2019-graph/">Graph Convolution Based Attention Model for Personalized Disease Prediction</a>
  </h3>

  
  <div class="article-style">
    <p>Clinicians implicitly incorporate the complementarity of multi-modal data for disease diagnosis. Often a varied order of importance for this heterogeneous data is considered for personalized decisions. Current learning-based methods have achieved better performance with uniform attention to individual information, but a very few have focused on patient-specific attention learning schemes for each modality. Towards this, we introduce a model which not only improves the disease prediction but also focuses on learning patient-specific order of importance for multi-modal data elements. In order to achieve this, we take advantage of LSTM-based attention mechanism and graph convolutional networks (GCNs) to design our model. GCNs learn multi-modal but class-specific features from the entire population of patients, whereas the attention mechanism optimally fuses these multi-modal features into a final decision, separately for each patient. In this paper, we apply the proposed approach for disease prediction task for Parkinson’s and Alzheimer’s using two public medical datasets.</p>
  </div>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://link.springer.com/chapter/10.1007/978-3-030-32251-9_14" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/kazi-2019-graph/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-from-graph/">
    Project
  </a>
  











  </div>
  

</div>

          
        
          
            





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/authors/anees-kazi/">Anees Kazi</a></span>, <span><a href="/authors/shayan-shekarforoush/">Shayan Shekarforoush</a></span>, <span><a href="/authors/s-arvind-krishna/">S Arvind Krishna</a></span>, <span><a href="/authors/hendrik-burwinkel/">Hendrik Burwinkel</a></span>, <span><a href="/authors/gerome-vivar/">Gerome Vivar</a></span>, <span><a href="/authors/karsten-kortum/">Karsten Kortüm</a></span>, <span><a href="/authors/seyed-ahmad-ahmadi/">Seyed-Ahmad Ahmadi</a></span>, <span><a href="/authors/shadi-albarqouni/">Shadi Albarqouni</a></span>, <span><a href="/authors/nassir-navab/">Nassir Navab</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January 2019
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      <em>International Conference on Information Processing in Medical Imaging</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/kazi-2019-inceptiongcn/">InceptionGCN: receptive field aware graph convolutional network for disease prediction</a>
  </h3>

  
  <div class="article-style">
    <p>Geometric deep learning provides a principled and versatile manner for the integration of imaging and non-imaging modalities in the medical domain. Graph Convolutional Networks (GCNs) in particular have been explored on a wide variety of problems such as disease prediction, segmentation, and matrix completion by leveraging large, multimodal datasets. In this paper, we introduce a new spectral domain architecture for deep learning on graphs for disease prediction. The novelty lies in defining geometric &lsquo;inception modules&rsquo; which are capable of capturing intra- and inter-graph structural heterogeneity during convolutions. We design filters with different kernel sizes to build our architecture. We show our disease prediction results on two publicly available datasets. Further, we provide insights on the behaviour of regular GCNs and our proposed model under varying input scenarios on simulated data.</p>
  </div>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://link.springer.com/chapter/10.1007/978-3-030-20351-1_6" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/kazi-2019-inceptiongcn/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-from-graph/">
    Project
  </a>
  











  </div>
  

</div>

          
        
          
            





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/authors/mhd-hasan-sarhan/">Mhd Hasan Sarhan</a></span>, <span><a href="/authors/shadi-albarqouni/">Shadi Albarqouni</a></span>, <span><a href="/authors/mehmet-yigitsoy/">Mehmet Yigitsoy</a></span>, <span><a href="/authors/nassir-navab/">Nassir Navab</a></span>, <span><a href="/authors/abouzar-eslami/">Abouzar Eslami</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January 2019
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      <em>International Conference on Medical Image Computing and Computer-Assisted Intervention</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/sarhan-2019-multi/">
      <img src="/publication/sarhan-2019-multi/featured_hu6475b771f2a64bdde0536af0030a9fe9_1079067_918x517_fill_q90_lanczos_smart1_3.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/sarhan-2019-multi/">Multi-scale Microaneurysms Segmentation Using Embedding Triplet Loss</a>
  </h3>

  
  <div class="article-style">
    <p>Deep learning techniques are recently being used in fundus image analysis and diabetic retinopathy detection. Microaneurysms are an important indicator of diabetic retinopathy progression. We introduce a two-stage deep learning approach for microaneurysms segmentation using multiple scales of the input with selective sampling and embedding triplet loss. The model first segments on two scales and then the segmentations are refined with a classification model. To enhance the discriminative power of the classification model, we incorporate triplet embedding loss with a selective sampling routine. The model is evaluated quantitatively to assess the segmentation performance and qualitatively to analyze the model predictions. This approach introduces a 30.29% relative improvement over the fully convolutional neural network.</p>
  </div>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.springerprofessional.de/en/multi-scale-microaneurysms-segmentation-using-embedding-triplet-/17254860" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/sarhan-2019-multi/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-from-graph/">
    Project
  </a>
  

  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-recognize/">
    Project
  </a>
  











  </div>
  

</div>

          
        
          
            





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/authors/anees-kazi/">Anees Kazi</a></span>, <span><a href="/authors/shayan-shekarforoush/">Shayan Shekarforoush</a></span>, <span><a href="/authors/karsten-kortuem/">Karsten Kortuem</a></span>, <span><a href="/authors/shadi-albarqouni/">Shadi Albarqouni</a></span>, <span><a href="/authors/nassir-navab/">Nassir Navab</a></span>, <span><a href="/authors/others/">others</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January 2019
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      <em>2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/kazi-2019-self/">Self-attention equipped graph convolutions for disease prediction</a>
  </h3>

  
  <div class="article-style">
    <p>Multi-modal data comprising imaging (MRI, fMRI, PET, etc.) and non-imaging (clinical test, demographics, etc.) data can be collected together and used for disease prediction. Such diverse data gives complementary information about the patient&rsquo;s condition to make an informed diagnosis. A model capable of leveraging the individuality of each multi-modal data is required for better disease prediction. We propose a graph convolution based deep model which takes into account the distinctiveness of each element of the multi-modal data. We incorporate a novel self-attention layer, which weights every element of the demographic data by exploring its relation to the underlying disease. We demonstrate the superiority of our developed technique in terms of computational speed and performance when compared to state-of-the-art methods. Our method outperforms other methods with a significant margin.</p>
  </div>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://ieeexplore.ieee.org/document/8759274" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/kazi-2019-self/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-from-graph/">
    Project
  </a>
  











  </div>
  

</div>

          
        
          
            





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/authors/ahmed-ayyad/">Ahmed Ayyad</a></span>, <span><a href="/authors/nassir-navab/">Nassir Navab</a></span>, <span><a href="/authors/mohamed-elhoseiny/">Mohamed Elhoseiny</a></span>, <span><a href="/authors/shadi-albarqouni/">Shadi Albarqouni</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January 2019
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      <em>Workshop on Multi-Task and Lifelong Reinforcement Learning at The International Conference in Machine Learning</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/ayyad-2019-semi/">
      <img src="/publication/ayyad-2019-semi/featured_huf5b6bf5f81a93bf71c98cba26cbf4beb_371302_918x517_fill_q90_lanczos_smart1_3.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/ayyad-2019-semi/">Semi-Supervised Few-Shot Learning with Prototypical Random Walks</a>
  </h3>

  
  <div class="article-style">
    <p>Recent progress has shown that few-shot learning can be improved with access to unlabelled data, known as semi-supervised few-shot learning(SS-FSL). We introduce an SS-FSL approach, dubbed as Prototypical Random Walk Networks(PRWN), built on top of Prototypical Networks (PN). We develop a random walk semi-supervised loss that enables the network to learn representations that are compact and well-separated. Our work is related to the very recent development on graph-based approaches for few-shot learning. However, we show that compact and well-separated class representations can be achieved by modeling our prototypical random walk notion without needing additional graph-NN parameters or requiring a transductive setting where collective test set is provided. Our model outperforms prior art in most benchmarks with significant improvements in some cases. For example, in a mini-Imagenet 5-shot classification task, we obtain 69.65% accuracy to the 64.59% state-of-the-art. Our model, trained with 40% of the data as labelled, compares competitively against fully supervised prototypical networks, trained on 100% of the labels, even outperforming it in the 1-shot mini-Imagenet case with 50.89% to 49.4% accuracy. We also show that our model is resistant to distractors, unlabeled data that does not belong to any of the training classes, and hence reflecting robustness to labelled/unlabelled class distribution mismatch. We also performed a challenging discriminative power test, showing a relative improvement on top of the baseline of ≈14% on 20 classes on mini-Imagenet and ≈60% on 800 classes on Omniglot. Code will be made available.</p>
  </div>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/arxiv.org/abs/1903.02164" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/ayyad-2019-semi/cite.bib">
  Cite
</button>


  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/sites.google.com/view/mtlrl" target="_blank" rel="noopener">
  Code
</a>




  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-learn/">
    Project
  </a>
  

  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-from-graph/">
    Project
  </a>
  











  </div>
  

</div>

          
        
          
            





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/authors/mai-bui/">Mai Bui</a></span>, <span><a href="/authors/sergey-zakharov/">Sergey Zakharov</a></span>, <span><a href="/authors/shadi-albarqouni/">Shadi Albarqouni</a></span>, <span><a href="/authors/slobodan-ilic/">Slobodan Ilic</a></span>, <span><a href="/authors/nassir-navab/">Nassir Navab</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January 2018
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      <em>2018 IEEE International Conference on Robotics and Automation (ICRA)</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/bui-2018-regression/">
      <img src="/publication/bui-2018-regression/featured_hu9475e40123017607cf3e014e405fbc8c_136639_918x517_fill_q90_lanczos_smart1.jpg" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/bui-2018-regression/">When regression meets manifold learning for object recognition and pose estimation</a>
  </h3>

  
  <div class="article-style">
    <p>In this work, we propose a method for object recognition and pose estimation from depth images using convolutional neural networks. Previous methods addressing this problem rely on manifold learning to learn low dimensional viewpoint descriptors and employ them in a nearest neighbor search on an estimated descriptor space. In comparison we create an efficient multi-task learning framework combining manifold descriptor learning and pose regression. By combining the strengths of manifold learning using triplet loss and pose regression, we could either estimate the pose directly reducing the complexity compared to NN search, or use learned descriptor for the NN descriptor matching. By in depth experimental evaluation of the novel loss function we observed that the view descriptors learned by the network are much more discriminative resulting in almost 30% increase regarding relative pose accuracy compared to related works. On the other hand, regarding directly regressed poses we obtained important improvement compared to simple pose regression. By leveraging the advantages of both manifold learning and regression tasks, we are able to improve the current state-of-the-art for object recognition and pose retrieval that we demonstrate through in depth experimental evaluation.</p>
  </div>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://ieeexplore.ieee.org/abstract/document/8460654/" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/bui-2018-regression/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-recognize/">
    Project
  </a>
  

  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-from-graph/">
    Project
  </a>
  











  </div>
  

</div>

          
        
          
            





  






<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/authors/s-albarqouni/">S Albarqouni</a></span>, <span><a href="/authors/m-baust/">M Baust</a></span>, <span><a href="/authors/s-conjeti/">S Conjeti</a></span>, <span><a href="/authors/a-al-amoudi/">A Al-Amoudi</a></span>, <span><a href="/authors/n-navab/">N Navab</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January 2015
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      <em>26th British Machine Vision Conference (BMVC), Swansea, UK</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/albarqouni-2015-multi/">
      <img src="/publication/albarqouni-2015-multi/featured_hu7eb670b47027e56ff926c6b030d4ca06_358237_918x517_fill_q90_lanczos_smart1_3.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/albarqouni-2015-multi/">Multi-scale Graph-based Guided Filter for De-noising Cryo-Electron Tomographic Data</a>
  </h3>

  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://dx.doi.org/10.5244/C.29.17" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/albarqouni-2015-multi/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-recognize/">
    Project
  </a>
  

  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-from-graph/">
    Project
  </a>
  











  </div>
  

</div>

          
        
      

      
      
      
    </div>
  </div>
</article>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.4.8/mermaid.min.js" integrity="sha256-lyWCDMnMeZiXRi7Zl54sZGKYmgQs4izcT7+tKc+KUBk=" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.b83f17b8257ec03d591fc1860efee439.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    ©Shadi Albarqouni 2022 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
