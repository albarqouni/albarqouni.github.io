<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Shadi Albarqouni">

  
  
  
    
  
  <meta name="description" content="Domain Adaptation, Style Transfer">

  
  <link rel="alternate" hreflang="en-us" href="https://albarqouni.github.io/project/learn-to-adapt/">

  


  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  





<script async src="https://www.googletagmanager.com/gtag/js?id=UA-73880662-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'UA-73880662-2', {});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  


  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu681563d5489cbd6b4a3381f376416aae_52869_32x32_fill_lanczos_center_3.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu681563d5489cbd6b4a3381f376416aae_52869_192x192_fill_lanczos_center_3.png">

  <link rel="canonical" href="https://albarqouni.github.io/project/learn-to-adapt/">

  
  
  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@ShadiAlbarqouni">
  <meta property="twitter:creator" content="@ShadiAlbarqouni">
  
  <meta property="og:site_name" content="Albarqouni Lab">
  <meta property="og:url" content="https://albarqouni.github.io/project/learn-to-adapt/">
  <meta property="og:title" content="Learn to Adapt | Albarqouni Lab">
  <meta property="og:description" content="Domain Adaptation, Style Transfer"><meta property="og:image" content="https://albarqouni.github.io/project/learn-to-adapt/featured.png">
  <meta property="twitter:image" content="https://albarqouni.github.io/project/learn-to-adapt/featured.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2020-04-06T00:00:00&#43;00:00">
    
    <meta property="article:modified_time" content="2020-04-12T00:45:50&#43;02:00">
  

  


    









<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://albarqouni.github.io/project/learn-to-adapt/"
  },
  "headline": "Learn to Adapt",
  
  "image": [
    "https://albarqouni.github.io/project/learn-to-adapt/featured.png"
  ],
  
  "datePublished": "2020-04-06T00:00:00Z",
  "dateModified": "2020-04-12T00:45:50+02:00",
  
  "author": {
    "@type": "Person",
    "name": "Shadi Albarqouni"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Albarqouni Lab",
    "logo": {
      "@type": "ImageObject",
      "url": "https://albarqouni.github.io/images/icon_hu681563d5489cbd6b4a3381f376416aae_52869_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "Domain Adaptation, Style Transfer"
}
</script>

  

  


  


  





  <title>Learn to Adapt | Albarqouni Lab</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  







<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Albarqouni Lab</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Albarqouni Lab</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#people"><span>Team</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#latest"><span>News</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Research</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#students"><span>Students</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#talks"><span>Community</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#featured"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#positions"><span>Open Positions</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/codes/"><span>Codes</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      

      

    </ul>

  </div>
</nav>


  <article class="article article-project">

  




















  
  
    
  


<div class="article-container pt-3">
  <h1>Learn to Adapt</h1>

  

  


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
          Last updated on
      
    
    Apr 12, 2020
  </span>
  

  

  

  
  
  

  
  

</div>

  













<div class="btn-links mb-3">
  
  








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1" href="https://twitter.com/ShadiAlbarqouni" target="_blank" rel="noopener">
    <i class="fab fa-twitter mr-1"></i>
    Follow
  </a>

  
  
  
    
  
  
  
  
  
    
    
      
    
  
  <a class="btn btn-outline-primary my-1 mr-1" href="/#contact" >
    <i class="fab fa-code mr-1"></i>
    Contribute
  </a>


</div>


</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 720px; max-height: 716px;">
  <div style="position: relative">
    <img src="/project/learn-to-adapt/featured_hu206510a70a17903071caa814626e64fc_1544025_720x0_resize_lanczos_3.png" alt="" class="featured-image">
    <span class="article-header-caption">Illustrative figure by Shadi Albarqouni</span>
  </div>
</div>



  <div class="article-container">

    <div class="article-style">
      <p>To build domain-agnostic models that are generalizable to a different domain, i.e., scanners, we have investigated three directions; First, <em>Style Transfer</em>, where the style/color of the source domain is transferred to match the target one.  Such style transfer is performed in the high-dimensional image space using adversarial learning, as shown in our papers on Histology Imaging (Lahiani <em>et al.</em> 2019a, Lahiani <em>et al.</em> 2019b, Shaban <em>et al.</em> 2019). Second, <em>Domain Adaptation</em>, where the distance between the features of the source and target domains are minimized. Such distance can be optimized in a supervised fashion, i.e., class aware, using angular cosine distance as shown in our paper on MS Lesion Segmentation in MR Imaging (Baur <em>et al.</em> 2017), or in an unsupervised way, i.e., class agnostic, using adversarial learning as explained in our article on Left atrium Segmentation in Ultrasound Imaging (Degel <em>et al.</em> 2018). Yet, another exciting direction that has been recently investigated in our paper (Lahiani <em>et al.</em> 2019c) is to disentangle the feature that is responsible for the style and color from the one responsible for the semantics.</p>
<p><img src="Baur_Degel_Shaban.jpeg" alt="Baur et al. 2017, Degel et al. 2018, and Shaban et al. 2019"></p>
<p><img src="lahiani2019c.jpeg" alt="Lahiani et al. 2019c"></p>
<h3 id="collaboration">Collaboration:</h3>
<ul>
<li>Eldad Klaiman, Roche Diagnostics GmbH</li>
<li>Georg Schummers and Matthias Friedrichs, TOMTEC Imaging Systems GmbH</li>
<li></li>
</ul>

    </div>

    





<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/deep-learning/">Deep Learning</a>
  
  <a class="badge badge-light" href="/tags/domain-adaptation/">Domain Adaptation</a>
  
  <a class="badge badge-light" href="/tags/medical-imaging/">Medical Imaging</a>
  
  <a class="badge badge-light" href="/tags/stain-normalization/">Stain Normalization</a>
  
  <a class="badge badge-light" href="/tags/generative-adversarial-networks/">Generative Adversarial Networks</a>
  
  <a class="badge badge-light" href="/tags/powerful-representation/">Powerful Representation</a>
  
  <a class="badge badge-light" href="/tags/style-transfer/">Style Transfer</a>
  
</div>



<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://albarqouni.github.io/project/learn-to-adapt/&amp;text=Learn%20to%20Adapt" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://albarqouni.github.io/project/learn-to-adapt/&amp;t=Learn%20to%20Adapt" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Learn%20to%20Adapt&amp;body=https://albarqouni.github.io/project/learn-to-adapt/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://albarqouni.github.io/project/learn-to-adapt/&amp;title=Learn%20to%20Adapt" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=Learn%20to%20Adapt%20https://albarqouni.github.io/project/learn-to-adapt/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https://albarqouni.github.io/project/learn-to-adapt/&amp;title=Learn%20to%20Adapt" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>












  
  





  
  
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <img class="avatar mr-3 avatar-circle" src="/authors/admin/avatar_huf6fe472177cdbbc11692e7b840700fd6_4388160_270x270_fill_q90_lanczos_center.jpg" alt="Shadi Albarqouni">
    

    <div class="media-body">
      <h5 class="card-title"><a href="/authors/admin/">Shadi Albarqouni</a></h5>
      <h6 class="card-subtitle">Professor of Computational Medical Imaging Research at 
<a href="https://www.uni-bonn.de/en" target="_blank" rel="noopener">University of Bonn</a> | AI Young Investigator Group Leader at 
<a href="https://www.helmholtz.ai/" target="_blank" rel="noopener">Helmholtz AI</a> | Affiliate Scientist at 
<a href="https://www.cs.cit.tum.de/camp/members/" target="_blank" rel="noopener">Technical University of Munich</a></h6>
      
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:shadi.albarqouni@tum.de" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://twitter.com/ShadiAlbarqouni" target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.de/citations?user=CPuApzoAAAAJ&amp;hl=en" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/albarqouni" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/shadialbarqouni/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://orcid.org/0000-0003-2157-2211" target="_blank" rel="noopener">
        <i class="ai ai-orcid"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://albarqouni.github.io/" target="_blank" rel="noopener">
        <i class="fas fa-globe-africa"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>












  
  
  <div class="article-widget content-widget-hr">
    <h3>Related</h3>
    <ul>
      
      <li><a href="/xtarx.github.io/StainGAN/">Staingan: Stain style transfer for digital histological images</a></li>
      
      <li><a href="/publication/lahiani-2020-seamless/">Seamless Virtual Whole Slide Image Synthesis and Validation Using Perceptual Embedding Consistency</a></li>
      
      <li><a href="/publication/lahiani-2019-perceptual/">Perceptual Embedding Consistency for Seamless Reconstruction of Tilewise Style Transfer</a></li>
      
      <li><a href="/publication/sarhan-2019-learning/">Learning interpretable disentangled representations using adversarial vaes</a></li>
      
      <li><a href="/publication/lahiani-2019-virtualization/">Virtualization of tissue staining in digital pathology using an unsupervised deep learning approach</a></li>
      
    </ul>
  </div>
  



    <div class="project-related-pages content-widget-hr">
      
      

      
      
      

      
      
      
        <h2>Publications</h2>
        
          
            





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/authors/agnieszka-tomczak/">Agnieszka Tomczak</a></span>, <span><a href="/authors/slobodan-ilic/">Slobodan Ilic</a></span>, <span><a href="/authors/gaby-marquardt/">Gaby Marquardt</a></span>, <span><a href="/authors/thomas-engel/">Thomas Engel</a></span>, <span><a href="/authors/nassir-navab/">Nassir Navab</a></span>, <span><a href="/authors/shadi-albarqouni/">Shadi Albarqouni</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January 2023
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      <em>IEEE Transactions on Medical Imaging</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/tomczak-2023-digital/">
      <img src="/publication/tomczak-2023-digital/featured_hu293254e6767ceaec2556caa497d56eea_98000_918x517_fill_q90_lanczos_smart1_3.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/tomczak-2023-digital/">Digital staining of white blood cells with confidence estimation</a>
  </h3>

  
  <div class="article-style">
    <p>Chemical staining of the blood smears is one of the crucial components of blood analysis. It is an expensive, lengthy and sensitive process, often prone to produce slight variations in colour and seen structures due to a lack of unified protocols across laboratories. Even though the current developments in deep generative modeling offer an opportunity to replace the chemical process with a digital one, there are specific safety-ensuring requirements due to the severe consequences of mistakes in a medical setting. Therefore digital staining system would profit from an additional confidence estimation quantifying the quality of the digitally stained white blood cell. To this aim, during the staining generation, we disentangle the latent space of the Generative Adversarial Network, obtaining separate representation s of the white blood cell and the staining. We estimate the generated image’s confidence of white blood cell structure and staining quality by corrupting these representations with noise and quantifying the information retained between multiple outputs. We show that confidence estimated in this way correlates with image quality measured in terms of LPIPS values calculated for the generated and ground truth stained images. We validate our method by performing digital staining of images captured with a Differential Inference Contrast microscope on a dataset composed of white blood cells of 24 patients. The high absolute value of the correlation between our confidence score and LPIPS demonstrates the effectiveness of our method, opening the possibility of predicting the quality of generated output and ensuring trustworthiness in medical safety-critical setup.</p>
  </div>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://ieeexplore.ieee.org/document/10248032" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/tomczak-2023-digital/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-adapt/">
    Project
  </a>
  

  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/affordable-ai/">
    Project
  </a>
  











  </div>
  

</div>

          
        
          
            





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/authors/agnieszka-tomczak/">Agnieszka Tomczak</a></span>, <span><a href="/authors/slobodan-ilic/">Slobodan Ilic</a></span>, <span><a href="/authors/gaby-marquardt/">Gaby Marquardt</a></span>, <span><a href="/authors/thomas-engel/">Thomas Engel</a></span>, <span><a href="/authors/frank-forster/">Frank Forster</a></span>, <span><a href="/authors/nassir-navab/">Nassir Navab</a></span>, <span><a href="/authors/shadi-albarqouni/">Shadi Albarqouni</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    December 2020
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      <em>IEEE Transactions on Medical Imaging</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/tomczak-2020-multi/">
      <img src="/publication/tomczak-2020-multi/featured_hu293254e6767ceaec2556caa497d56eea_98000_918x517_fill_q90_lanczos_smart1_3.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/tomczak-2020-multi/">Multi-task multi-domain learning for digital staining and classification of leukocytes</a>
  </h3>

  
  <div class="article-style">
    <p>oking stained images preserving the inter-cellular structures, crucial for the medical experts to perform classification. We achieve better structure preservation by adding auxiliary tasks of segmentation and direct reconstruction. Segmentation enforces that the network learns to generate correct nucleus and cytoplasm shape, while direct reconstruction enforces reliable translation between the matching images across domains. Besides, we build a robust domain agnostic latent space by injecting the target domain label directly to the generator, i.e., bypassing the encoder. It allows the encoder to extract features independently of the target domain and enables an automated domain invariant classification of the white blood cells. We validated our method on a large dataset composed of leukocytes of 24 patients, achieving state-of-the-art performance on both digital staining and classification tasks.</p>
  </div>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://ieeexplore.ieee.org/document/9301322" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/tomczak-2020-multi/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-recognize/">
    Project
  </a>
  

  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-adapt/">
    Project
  </a>
  











  </div>
  

</div>

          
        
          
            





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/authors/mhd-hasan-sarhan/">Mhd Hasan Sarhan</a></span>, <span><a href="/authors/nassir-navab/">Nassir Navab</a></span>, <span><a href="/authors/abouzar-eslami/">Abouzar Eslami</a></span>, <span><a href="/authors/shadi-albarqouni/">Shadi Albarqouni</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    August 2020
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      <em>16th European Conference on Computer Vision (ECCV)</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/sarhan-2020-fairness/">
      <img src="/publication/sarhan-2020-fairness/featured_hu236b2cb90c7efe8b9240a363bdd17028_58000_918x517_fill_q90_lanczos_smart1_3.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/sarhan-2020-fairness/">Fairness by Learning Orthogonal Disentangled Representations</a>
  </h3>

  
  <div class="article-style">
    <p>Learning discriminative powerful representations is a crucial step for machine learning systems. Introducing invariance against arbitrary nuisance or sensitive attributes while performing well on specific tasks is an important problem in representation learning. This is mostly approached by purging the sensitive information from learned representations. In this paper, we propose a novel disentanglement approach to invariant representation problem. We disentangle the meaningful and sensitive representations by enforcing orthogonality constraints as a proxy for independence. We explicitly enforce the meaningful representation to be agnostic to sensitive information by entropy maximization. The proposed approach is evaluated on five publicly available datasets and compared with state of the art methods for learning fairness and invariance achieving the state of the art performance on three datasets and comparable performance on the rest. Further, we perform an ablative study to evaluate the effect of each component.</p>
  </div>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123740732.pdf" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/sarhan-2020-fairness/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-reason-and-explain/">
    Project
  </a>
  

  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-adapt/">
    Project
  </a>
  











  </div>
  

</div>

          
        
          
            





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/authors/amal-lahiani/">Amal Lahiani</a></span>, <span><a href="/authors/irina-klaman/">Irina Klaman</a></span>, <span><a href="/authors/nassir-navab/">Nassir Navab</a></span>, <span><a href="/authors/shadi-albarqouni/">Shadi Albarqouni</a></span>, <span><a href="/authors/eldad-klaiman/">Eldad Klaiman</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    February 2020
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      <em>IEEE Journal of Biomedical and Health Informatics</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/lahiani-2020-seamless/">
      <img src="/publication/lahiani-2020-seamless/featured_hud6e067331272fb558abd612ed8cb49f5_27701_918x517_fill_q90_lanczos_smart1.jpeg" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/lahiani-2020-seamless/">Seamless Virtual Whole Slide Image Synthesis and Validation Using Perceptual Embedding Consistency</a>
  </h3>

  
  <div class="article-style">
    <p>Stain virtualization is an application with growing interest in digital pathology allowing simulation of stained tissue images thus saving lab and tissue resources. Thanks to the success of Generative Adversarial Networks (GANs) and the progress of unsupervised learning, unsupervised style transfer GANs have been successfully used to generate realistic, clinically meaningful and interpretable images. The large size of high resolution Whole Slide Images (WSIs) presents an additional computational challenge. This makes tilewise processing necessary during training and inference of deep learning networks. Instance normalization has a substantial positive effect in style transfer GAN applications but with tilewise inference, it has the tendency to cause a tiling artifact in reconstructed WSIs. In this paper we propose a novel perceptual embedding consistency (PEC) loss forcing the network to learn color, contrast and brightness invariant features in the latent space and hence substantially reducing the aforementioned tiling artifact. Our approach results in more seamless reconstruction of the virtual WSIs. We validate our method quantitatively by comparing the virtually generated images to their corresponding consecutive real stained images.We compare our results to state-of-the-art unsupervised style transfer methods and to the measures obtained from consecutive real stained tissue slide images. We demonstrate our hypothesis about the effect of the PEC loss by comparing model robustness to color, contrast and brightness perturbations and visualizing bottleneck embeddings. We validate the robustness of the bottleneck feature maps by measuring their sensitivity to the different perturbations and using them in a tumor segmentation task. Additionally, we propose a preliminary validation of the virtual staining application by comparing interpretation of 2 pathologists on real and virtual tiles and inter-pathologist agreement</p>
  </div>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.ncbi.nlm.nih.gov/pubmed/32086223" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/lahiani-2020-seamless/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-adapt/">
    Project
  </a>
  











  </div>
  

</div>

          
        
          
            





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/authors/amal-lahiani/">Amal Lahiani</a></span>, <span><a href="/authors/nassir-navab/">Nassir Navab</a></span>, <span><a href="/authors/shadi-albarqouni/">Shadi Albarqouni</a></span>, <span><a href="/authors/eldad-klaiman/">Eldad Klaiman</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January 2019
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      <em>Medical Image Computing and Computer Assisted Intervention</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/lahiani-2019-perceptual/">Perceptual Embedding Consistency for Seamless Reconstruction of Tilewise Style Transfer</a>
  </h3>

  
  <div class="article-style">
    <p>Style transfer is a field with growing interest and use cases in deep learning. Recent work has shown Generative Adversarial Networks(GANs) can be used to create realistic images of virtually stained slide images in digital pathology with clinically validated interpretability. Digital pathology images are typically of extremely high resolution, making tilewise analysis necessary for deep learning applications. It has been shown that image generators with instance normalization can cause a tiling artifact when a large image is reconstructed from the tilewise analysis. We introduce a novel perceptual embedding consistency loss significantly reducing the tiling artifact created in the reconstructed whole slide image (WSI). We validate our results by comparing virtually stained slide images with consecutive real stained tissue slide images. We also demonstrate that our model is more robust to contrast, color and brightness perturbations by running comparative sensitivity analysis tests.</p>
  </div>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://link.springer.com/chapter/10.1007/978-3-030-32239-7_63" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/lahiani-2019-perceptual/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-adapt/">
    Project
  </a>
  











  </div>
  

</div>

          
        
          
            





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/authors/m-tarek-shaban/">M Tarek Shaban</a></span>, <span><a href="/authors/christoph-baur/">Christoph Baur</a></span>, <span><a href="/authors/nassir-navab/">Nassir Navab</a></span>, <span><a href="/authors/shadi-albarqouni/">Shadi Albarqouni</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January 2019
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      <em>2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/xtarx.github.io/StainGAN/">
      <img src="/xtarx.github.io/StainGAN/featured_hudc3dac6f0b406e032ea7f48175b415ed_112466_918x517_fill_q90_lanczos_smart1_3.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/xtarx.github.io/StainGAN/">Staingan: Stain style transfer for digital histological images</a>
  </h3>

  
  <div class="article-style">
    <p>Digitized Histological diagnosis is in increasing demand. However, color variations due to various factors are imposing obstacles to the diagnosis process. The problem of stain color variations is a well-defined problem with many proposed solutions. Most of these solutions are highly dependent on a reference template slide. We propose a deep-learning solution inspired by cycle consistency that is trained end-to-end, eliminating the need for an expert to pick a representative reference slide. Our approach showed superior results quantitatively and qualitatively against the state of the art methods. We further validated our method on a clinical use-case, namely Breast Cancer tumor classification, showing 16% increase in AUC</p>
  </div>
  

  
  <div class="btn-links">
    








  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/xtarx.github.io/StainGAN/shaban-2019-staingan.pdf" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/xtarx.github.io/StainGAN/cite.bib">
  Cite
</button>


  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/github.com/xtarx/StainGAN" target="_blank" rel="noopener">
  Code
</a>




  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-adapt/">
    Project
  </a>
  

  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/affordable-ai/">
    Project
  </a>
  











  </div>
  

</div>

          
        
          
            





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/authors/amal-lahiani/">Amal Lahiani</a></span>, <span><a href="/authors/jacob-gildenblat/">Jacob Gildenblat</a></span>, <span><a href="/authors/irina-klaman/">Irina Klaman</a></span>, <span><a href="/authors/shadi-albarqouni/">Shadi Albarqouni</a></span>, <span><a href="/authors/nassir-navab/">Nassir Navab</a></span>, <span><a href="/authors/eldad-klaiman/">Eldad Klaiman</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January 2019
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      <em>European Congress on Digital Pathology</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/lahiani-2019-virtualization/">Virtualization of tissue staining in digital pathology using an unsupervised deep learning approach</a>
  </h3>

  
  <div class="article-style">
    <p>Histopathological evaluation of tissue samples is a key practice in patient diagnosis and drug development, especially in oncology. Historically, Hematoxylin and Eosin (H&amp;E) has been used by pathologists as a gold standard staining. However, in many cases, various target specific stains, including immunohistochemistry (IHC), are needed in order to highlight specific structures in the tissue. As tissue is scarce and staining procedures are tedious, it would be beneficial to generate images of stained tissue virtually. Virtual staining could also generate in-silico multiplexing of different stains on the same tissue segment. In this paper, we present a sample application that generates FAP-CK virtual IHC images from Ki67-CD8 real IHC images using an unsupervised deep learning approach based on CycleGAN. We also propose a method to deal with tiling artifacts caused by normalization layers and we validate our approach by comparing the results of tissue analysis algorithms for virtual and real images.</p>
  </div>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://link.springer.com/chapter/10.1007/978-3-030-23937-4_6" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/lahiani-2019-virtualization/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-adapt/">
    Project
  </a>
  











  </div>
  

</div>

          
        
          
            





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/authors/markus-a-degel/">Markus A Degel</a></span>, <span><a href="/authors/nassir-navab/">Nassir Navab</a></span>, <span><a href="/authors/shadi-albarqouni/">Shadi Albarqouni</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January 2018
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      <em>International Conference on Medical Image Computing and Computer-Assisted Intervention</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/degel-2018-domain/">
      <img src="/publication/degel-2018-domain/featured_hu9aac1821881c2a3af170a15363ee778a_36850_918x517_fill_q90_lanczos_smart1_3.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/degel-2018-domain/">Domain and geometry agnostic CNNs for left atrium segmentation in 3D ultrasound</a>
  </h3>

  
  <div class="article-style">
    <p>Segmentation of the left atrium and deriving its size can help to predict and detect various cardiovascular conditions. Automation of this process in 3D Ultrasound image data is desirable, since manual delineations are time-consuming, challenging and observer-dependent. Convolutional neural networks have made improvements in computer vision and in medical image analysis. They have successfully been applied to segmentation tasks and were extended to work on volumetric data. In this paper we introduce a combined deep-learning based approach on volumetric segmentation in Ultrasound acquisitions with incorporation of prior knowledge about left atrial shape and imaging device. The results show, that including a shape prior helps the domain adaptation and the accuracy of segmentation is further increased with adversarial learning.</p>
  </div>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://link.springer.com/chapter/10.1007/978-3-030-00937-3_72" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/degel-2018-domain/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-adapt/">
    Project
  </a>
  











  </div>
  

</div>

          
        
          
            





  






<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/authors/amal-lahiani/">Amal Lahiani</a></span>, <span><a href="/authors/jacob-gildenblat/">Jacob Gildenblat</a></span>, <span><a href="/authors/irina-klaman/">Irina Klaman</a></span>, <span><a href="/authors/nassir-navab/">Nassir Navab</a></span>, <span><a href="/authors/eldad-klaiman/">Eldad Klaiman</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January 2018
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      <em>arXiv preprint arXiv:1805.06958</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/lahiani-2018-generalizing/">Generalizing multistain immunohistochemistry tissue segmentation using one-shot color deconvolution deep neural networks</a>
  </h3>

  

  
  <div class="btn-links">
    








  





<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/lahiani-2018-generalizing/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-adapt/">
    Project
  </a>
  











  </div>
  

</div>

          
        
          
            





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/authors/christoph-baur/">Christoph Baur</a></span>, <span><a href="/authors/shadi-albarqouni/">Shadi Albarqouni</a></span>, <span><a href="/authors/nassir-navab/">Nassir Navab</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January 2017
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      <em>International Conference on Medical Image Computing and Computer-Assisted Intervention</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/baur-2017-semi/">
      <img src="/publication/baur-2017-semi/featured_hu22ee437d8f73003d235f78f5a8291da7_257728_918x517_fill_q90_lanczos_smart1_3.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/baur-2017-semi/">Semi-supervised deep learning for fully convolutional networks</a>
  </h3>

  
  <div class="article-style">
    <p>Deep learning usually requires large amounts of labeled training data, but annotating data is costly and tedious. The framework of semi-supervised learning provides the means to use both labeled data and arbitrary amounts of unlabeled data for training. Recently, semi-supervised deep learning has been intensively studied for standard CNN architectures. However, Fully Convolutional Networks (FCNs) set the state-of-the-art for many image segmentation tasks. To the best of our knowledge, there is no existing semi-supervised learning method for such FCNs yet. We lift the concept of auxiliary manifold embedding for semi-supervised learning to FCNs with the help of Random Feature Embedding. In our experiments on the challenging task of MS Lesion Segmentation, we leverage the proposed framework for the purpose of domain adaptation and report substantial improvements over the baseline model.</p>
  </div>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/1703.06000.pdf" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/baur-2017-semi/cite.bib">
  Cite
</button>


  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/bumuckl/SemiSupervisedDLForFCNs" target="_blank" rel="noopener">
  Code
</a>




  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-recognize/">
    Project
  </a>
  

  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-adapt/">
    Project
  </a>
  











  </div>
  

</div>

          
        
          
            





  






<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/authors/abhishek-vahadane/">Abhishek Vahadane</a></span>, <span><a href="/authors/tingying-peng/">Tingying Peng</a></span>, <span><a href="/authors/amit-sethi/">Amit Sethi</a></span>, <span><a href="/authors/shadi-albarqouni/">Shadi Albarqouni</a></span>, <span><a href="/authors/lichao-wang/">Lichao Wang</a></span>, <span><a href="/authors/maximilian-baust/">Maximilian Baust</a></span>, <span><a href="/authors/katja-steiger/">Katja Steiger</a></span>, <span><a href="/authors/anna-melissa-schlitter/">Anna Melissa Schlitter</a></span>, <span><a href="/authors/irene-esposito/">Irene Esposito</a></span>, <span><a href="/authors/nassir-navab/">Nassir Navab</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January 2016
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      <em>IEEE transactions on medical imaging</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/vahadane-2016-structure/">Structure-preserving color normalization and sparse stain separation for histological images</a>
  </h3>

  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://ieeexplore.ieee.org/document/7164042" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/vahadane-2016-structure/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-adapt/">
    Project
  </a>
  











  </div>
  

</div>

          
        
      

      
      
      
        <h2>Talks</h2>
        
          
            








  
  





  


<div class="media stream-item">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0">
      <a href="/talk/eops2024/" >Invited Keynote Lecture on AI in Ophthalmology and Pathology</a>
    </h3>

    
    <div class="article-style">
      I was invited to give a Keynote Lecture on AI in Ophthalmology and Pathology to present a few works on Histopathology; Mitotoc figure detection in Breast Cancer, Domain Adaptation from H&amp;E Imaging to IHC imaging among others. Thanks Prof. Martina C. Herwig-Carl for the invitation and warm hospitality!
    </div>
    

    <div class="stream-meta article-metadata">

      
      <div>
        <span>
          Jun 12, 2024 &amp;mdash; Jun 15, 2024
        </span>
        
        <span class="middot-divider"></span>
        <span>Bonn, Germany</span>
        
      </div>
      

      
    </div>

    
    <div class="btn-links">
      








  









  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-recognize/">
    Project
  </a>
  

  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-adapt/">
    Project
  </a>
  










  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://twitter.com/ShadiAlbarqouni" target="_blank" rel="noopener">
    <i class="fab fa-twitter mr-1"></i>
    Follow
  </a>


    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/talk/eops2024/" >
      <img src="/talk/eops2024/featured_hu31c21b038db42b6a467d2098ea829cbb_1113351_150x0_resize_q90_lanczos.JPG" alt="">
    </a>
    
  </div>
</div>

          
        
          
            








  
  






<div class="media stream-item">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0">
      <a href="/talk/dart2020/" >Organizing Committee Member at MICCAI DART 2020</a>
    </h3>

    

    <div class="stream-meta article-metadata">

      
      <div>
        <span>
          Apr 1, 2020 &amp;mdash;
        </span>
        
        <span class="middot-divider"></span>
        <span>MICCAI 2020, Lima, Peru</span>
        
      </div>
      

      
    </div>

    
    <div class="btn-links">
      








  









  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-adapt/">
    Project
  </a>
  

  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-recognize/">
    Project
  </a>
  










  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://twitter.com/ShadiAlbarqouni" target="_blank" rel="noopener">
    <i class="fab fa-twitter mr-1"></i>
    Follow
  </a>


    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/talk/dart2020/" >
      <img src="/talk/dart2020/featured_hu32d956bc8e50306ede2f4c6bd5595ac7_60420_150x0_resize_q90_lanczos.jpg" alt="">
    </a>
    
  </div>
</div>

          
        
          
            








  
  






<div class="media stream-item">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0">
      <a href="/talk/dart2019/" >Organizing Committee Member at MICCAI DART 2019</a>
    </h3>

    

    <div class="stream-meta article-metadata">

      
      <div>
        <span>
          Oct 13, 2019 16:00
        </span>
        
        <span class="middot-divider"></span>
        <span>MICCAI 2019, Shenzhen, China</span>
        
      </div>
      

      
    </div>

    
    <div class="btn-links">
      








  









  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-adapt/">
    Project
  </a>
  

  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-recognize/">
    Project
  </a>
  










  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://twitter.com/ShadiAlbarqouni" target="_blank" rel="noopener">
    <i class="fab fa-twitter mr-1"></i>
    Follow
  </a>


    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/talk/dart2019/" >
      <img src="/talk/dart2019/featured_huffb50573c9fb28cd932a2f7ea1069117_139109_150x0_resize_q90_lanczos.jpeg" alt="">
    </a>
    
  </div>
</div>

          
        
          
            








  
  






<div class="media stream-item">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0">
      <a href="/talk/compay2019/" >Organizing Committee Member at MICCAI COMPAY 2019</a>
    </h3>

    

    <div class="stream-meta article-metadata">

      
      <div>
        <span>
          Oct 13, 2019
        </span>
        
        <span class="middot-divider"></span>
        <span>MICCAI 2019, Shenzhen, China</span>
        
      </div>
      

      
    </div>

    
    <div class="btn-links">
      








  









  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-recognize/">
    Project
  </a>
  

  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-to-adapt/">
    Project
  </a>
  

  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/learn-from-crowds/">
    Project
  </a>
  










  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://twitter.com/ShadiAlbarqouni" target="_blank" rel="noopener">
    <i class="fab fa-twitter mr-1"></i>
    Follow
  </a>


    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/talk/compay2019/" >
      <img src="/talk/compay2019/featured_hu045c8a8c53dac57fd738878d9f4bc6c0_140710_150x0_resize_q90_lanczos.jpeg" alt="">
    </a>
    
  </div>
</div>

          
        
      
    </div>
  </div>
</article>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.4.8/mermaid.min.js" integrity="sha256-lyWCDMnMeZiXRi7Zl54sZGKYmgQs4izcT7+tKc+KUBk=" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.5cbe51271615d69caead0155ce0cb8ce.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    ©Shadi Albarqouni 2024 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
